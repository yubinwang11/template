@InProceedings{pmlr-v133-laurent21a,
  title = 	 {Flatland Competition 2020: MAPF and MARL for Efficient Train Coordination on a Grid World},
  author =       {Laurent, Florian and Schneider, Manuel and Scheller, Christian and Watson, Jeremy and Li, Jiaoyang and Chen, Zhe and Zheng, Yi and Chan, Shao-Hung and Makhnev, Konstantin and Svidchenko, Oleg and Egorov, Vladimir and Ivanov, Dmitry and Shpilman, Aleksei and Spirovska, Evgenija and Tanevski, Oliver and Nikov, Aleksandar and Grunder, Ramon and Galevski, David and Mitrovski, Jakov and Sartoretti, Guillaume and Luo, Zhiyao and Damani, Mehul and Bhattacharya, Nilabha and Agarwal, Shivam and Egli, Adrian and Nygren, Erik and Mohanty, Sharada},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {275--301},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  abbr={NeurIPS}, 
  pdf = 	 {http://proceedings.mlr.press/v133/laurent21a/laurent21a.pdf},
  url = 	 {http://proceedings.mlr.press/v133/laurent21a.html},
  abstract = 	 {The Flatland competition aimed at finding novel approaches to solve the vehicle re-scheduling problem (VRSP). The VRSP is concerned with scheduling trips in traffic networks and the re-scheduling of vehicles when disruptions occur, for example the breakdown of a vehicle. While solving the VRSP in various settings has been an active area in operations research (OR) for decades, the ever-growing complexity of modern railway networks makes dynamic real-time scheduling of traffic virtually impossible. Recently, multi-agent reinforcement learning (MARL) has successfully tackled challenging tasks where many agents need to be coordinated, such as multiplayer video games. However, the coordination of hundreds of agents in a real-life setting like a railway network remains challenging and the Flatland environment used for the competition models these real-world properties in a simplified manner. Submissions had to bring as many trains (agents) to their target stations in as little time as possible. While the best submissions were in the OR category, participants found many promising MARL approaches. Using both centralized and decentralized learning based approaches, top submissions used graph representations of the environment to construct tree-based observations. Further, different coordination mechanisms were implemented, such as communication and prioritization between agents. This paper presents the competition setup, four outstanding solutions to the competition, and a cross-comparison between them.	}
}


@ARTICLE{9366340,
  author={Damani, Mehul and Luo, Zhiyao and Wenzel, Emerson and Sartoretti, Guillaume},
  abbr={IEEE-RAL, ICRA},
  journal={IEEE Robotics and Automation Letters}, 
  title={PRIMAL2: Pathfinding Via Reinforcement and Imitation Multi-Agent Learning - Lifelong}, 
  year={2021},
  volume={6},
  number={2},
  pages={2666-2673},
  doi={10.1109/LRA.2021.3062803}, selected={true}, pdf={primal.pdf}, url = {https://arxiv.org/abs/2010.08184},arxiv={2010.08184},code={https://github.com/marmotlab/PRIMAL2}}

  }


